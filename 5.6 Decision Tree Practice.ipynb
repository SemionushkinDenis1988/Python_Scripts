{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Начнём с простого - создайте Decision Tree классификатор, используя одноимённый класс из библиотеки sklearn и сохраните\n",
    "#его в переменную dt.\n",
    "#https://scikit-learn.org/stable/modules/tree.html - Decision Tree классификатор\n",
    "#У дерева должны быть следующие параметры:\n",
    "#максимальная глубина - 5 уровней\n",
    "#минимальное число образцов в вершине для разделения - 5\n",
    "#Подробнее узнать об имеющихся параметрах Decision Tree можно узнать в документации.\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(max_depth=5, min_samples_split=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Скачайте набор данных с тремя переменными: sex, exang, num. Представьте, что при помощи дерева решений мы хотим \n",
    "#классифицировать есть или нет у пациента заболевание сердца (переменная num), основываясь на двух признаках: пол (sex) и \n",
    "#наличие/отсутсвие стенокардии (exang). Обучите дерево решений на этих данных, используйте entropy в качестве критерия.\n",
    "\n",
    "#Укажите, чему будет равняться значение Information Gain для переменной,  которая будет помещена в корень дерева.\n",
    "\n",
    "#В ответе необходимо указать число с точностью 3 знака после запятой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"train_data_tree.csv\")\n",
    "X_train = train_data[['sex', 'exang']]\n",
    "y_train = train_data.num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(criterion=\"entropy\")\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sb\n",
    "from sklearn import tree\n",
    "tree.plot_tree(dt, filled=True)\n",
    "# 0 - индекс корня\n",
    "l_node = dt.tree_.children_left[0] # индекс корня левого поддерева\n",
    "n1 = dt.tree_.n_node_samples[l_node] # сэмплов в левом поддереве\n",
    "e1 = dt.tree_.impurity[l_node] # энтропия в корне левого поддерева"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([238, 157,  53, 104,  81,  16,  65], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.tree_.n_node_samples  #количество сэмплов(рассматриваемых вариантов) каждой ветки дерева"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99587   , 0.90271134, 0.61219613, 0.97315604, 0.82562653,\n",
       "       0.954434  , 0.77934984])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.tree_.impurity  #Энтропия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11920588235294116"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IG = 0.996 - 157*0.903/238 - 81*0.826/238 #расчет information gain\n",
    "IG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25) #генерация трейн и тест множеств\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "predicted = dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 2, 2, 0, 2, 2, 2, 0, 0, 2, 0, 1, 0, 1, 0, 2, 2, 0, 1,\n",
       "       2, 0, 1, 1, 1, 2, 0, 2, 0, 2, 2, 2, 1, 0, 2, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1)train_test_split Разделение имеющихся данных на тестовый и тренировочный наборы\n",
    "#2)cross_validateРазделение данных на kk частей, тренировка на k - 1k−1 частях, тестирование на оставшейся; так для каждой части\n",
    "#3)ShuffleSplitАналог обычного разделения на тестовый и тренировочный датасэты с большим числом таких случайных разделений\n",
    "#4)LeaveOneOutРазделение данных на 2 части с n - 1n−1 и 11 наблюдением, на первой идёт тренировка, 2-ая - для предсказания; \n",
    "#каждое наблюдение побывает во второй части\n",
    "#5)LeavePOutРазделение данных на 2 части с n - kn−k и kk наблюдениями, на первой идёт тренировка, 2-ая - для предсказания; \n",
    "#идёт ротация по всем наблюдениям\n",
    "#6)StratifiedKFoldk-fold cross validation с учётом количества наблюдений в классах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Существуют различные способы вызова кросс-валидации в sklearn, например\n",
    "#cross_val_predict(estimator, x, y, cv=bar)\n",
    "#где estimator - предсказывающая модель, а bar - число блоков при k-fold кросс-валидации или объект из sklearn.model_selection, \n",
    "#позволяющий осуществлять кросс-валидацию по другой стратегии.\n",
    "#Мы будем использовать другой способ - GridSearchCV, отбирающий лучшую модель по заданным параметрам, проводя кросс-валидацию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Одно дерево - хорошо, но где гарантии, что оно является лучшим, или хотя бы близко к нему? Одним из способов найти \n",
    "#более-менее оптимальный набор параметров дерева является перебор множества деревьев с разными параметрами и выбор подходящего.\n",
    "#Для этой цели существует класс GridSearchCV, перебирающий каждое из сочетаний параметров среди заданных для модели, \n",
    "#обучающий её на данных и проводящих кросс-валидацию. После этого в аттрибуте .best_estimator_ храниться модель с \n",
    "#лучшими параметрами. Это применимо не только к деревьям, но и к другим моделям sklearn.\n",
    "\n",
    "#Теперь задание - осуществите перебор всех деревьев на данных ириса по следующим параметрам:\n",
    "#максимальная глубина - от 1 до 10 уровней\n",
    "#минимальное число проб для разделения - от 2 до 10\n",
    "#минимальное число проб в листе - от 1 до 10\n",
    "#и сохраните в переменную best_tree лучшее дерево. Переменную с GridSearchCV назовите search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Titan\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\Titan\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "\n",
    "iris = load_iris()\n",
    "x = iris.data\n",
    "y = iris.target\n",
    "parameter_grid = {\n",
    "            'max_depth': range(1,10),\n",
    "            'min_samples_split': range(2,10),\n",
    "            'min_samples_leaf':range(1,10)\n",
    "    }\n",
    "df = DecisionTreeClassifier()\n",
    "search=GridSearchCV(df,parameter_grid)\n",
    "search.fit(x, y)\n",
    "best_tree = search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Такие маны и примеры могут помочь в решении :\n",
    "\n",
    "#https://mlbootcamp.ru/article/tutorial/\n",
    "\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV\n",
    "\n",
    "#https://qa-help.ru/questions/parametr-oczenki-gridsearchcv-s-ispolzovaniem-scoring-f1-ili-scoring-none-po-umolchaniyu-ispolzuet-tochnost-daet-tot-zhe-rezultat\n",
    "\n",
    "#https://habr.com/ru/company/ods/blog/322534/\n",
    "\n",
    "#http://qaru.site/questions/251472/how-to-get-best-estimator-on-gridsearchcv-random-forest-classifier-scikit\n",
    "\n",
    "#https://www.coursera.org/lecture/supervised-learning/podbor-paramietrov-po-sietkie-sklearn-grid-search-Cug3z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Titan\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  23 out of  30 | elapsed:    0.6s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    0.6s finished\n",
      "C:\\Users\\Titan\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "x = iris.data\n",
    "y = iris.target\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "clf.fit(x, y)\n",
    "\n",
    "parameters = {'max_depth': range(1, 10),\n",
    "             'min_samples_leaf': range(1, 10),\n",
    "             'min_samples_split': range(2, 10)}\n",
    "\n",
    "search = RandomizedSearchCV(clf, parameters, verbose=1, n_jobs=-1)\n",
    "search.fit(x,y)\n",
    "best_tree = search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-deb481d9064e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     }\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'y'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameter_grid = {\n",
    "            'max_depth': range(1,10),\n",
    "            'min_samples_split': range(2,10),\n",
    "            'min_samples_leaf':range(1,10)\n",
    "    }\n",
    "\n",
    "x = train.drop('y',axis = 1)\n",
    "y = train.y\n",
    "\n",
    "df = DecisionTreeClassifier()\n",
    "search=GridSearchCV(df,parameter_grid)  \n",
    "search.fit(x, y)\n",
    "best_tree = search.best_estimator_         #выбираем лучшее дерево\n",
    "predictions = best_tree.predict(test) #предсказываем с помощью лучшего дерева"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-33e601c0e5a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# разбиваем датафрейм train на X и y\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mx_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"y\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"y\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# разбиваем датафрейм train на X и y\n",
    "x_train = train.drop([\"y\"], axis=1)\n",
    "y_train = train[\"y\"]\n",
    "\n",
    "# создаем словарь с параметрами, которые хотим проверить\n",
    "params = {\"max_depth\": range(1,11), \"min_samples_split\":range(2,11), \"min_samples_leaf\":range(1,11)}\n",
    "\n",
    "# создаем экзмпляр дерева\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "# создаем экземпляр GridSearchCV\n",
    "search = GridSearchCV(dt, params, cv=5)\n",
    "\n",
    "# обучаем или ищем лучшее дерево\n",
    "search.fit(x_train,y_train)\n",
    "\n",
    "# сохраням лучшее дерево по мнению GridSearchCV\n",
    "best_tree = search.best_estimator_\n",
    "\n",
    "# делаем предсказания по лучшему дереву на датасете test\n",
    "predictions = best_tree.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#При классификации модель может допускать ошибки, присваивая наблюдению неверный класс. Существуют различные метрики\n",
    "#оценки качества предсказаний, которые базируются на 4-ёх параметрах - true positive, false positive, false negative и \n",
    "#true negative, соответствующих тому какой класс был присвоен наблюдениям каждого из классов. Матрицу из 4-ёх (в случае \n",
    "#бинарной классификации) этих параметров называют confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-79013248b097>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mconf_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m#https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "conf_matrix = confusion_matrix(y, predictions)\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#F 1−score Отношение удвоенного произведения precision и recall к их сумме\n",
    "#RecallRecall, True Positive RateTruePositiveRate, SensitivitySensitivity Отношение правильно определённых положительных \n",
    "#случаев ко всем положительным - показывает какую часть положительных случаев модель правильно классифицирует\n",
    "#PrecisionPrecision Отношение правильно определённых положительных наблюдений ко всем определённым как положительные\n",
    "#AccuracyAccuracy Отношение правильно классифицированных наблюдений ко всем\n",
    "#SpecificitySpecificity, True Negative RateTrueNegativeRate Отношение правильно определённых отрицательных случаев ко \n",
    "#всем отрицательным - показывает какую часть отрицательных случаев модель правильно классифицирует"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
